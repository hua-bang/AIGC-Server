#!/bin/bash

# HTTP/1.1 Chunked Transfer Encoding æµ‹è¯•è„šæœ¬
# ä½¿ç”¨ curl å‘½ä»¤è¡Œå·¥å…·æµ‹è¯•å„ç§ chunked ç«¯ç‚¹

echo "ğŸŒŠ HTTP/1.1 Chunked Transfer Encoding æµ‹è¯•"
echo "=========================================="
echo ""

# æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
echo "ğŸ“¡ æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€..."
if ! curl -s --connect-timeout 3 http://localhost:3000 > /dev/null; then
    echo "âŒ æœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡å™¨ï¼š"
    echo "   npm install && npm start"
    exit 1
fi
echo "âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸"
echo ""

# æµ‹è¯•åŸºç¡€æ–‡æœ¬æ•°æ®æµ
echo "ğŸ“ æµ‹è¯•åŸºç¡€æ–‡æœ¬æ•°æ®æµ (/chunked-data)"
echo "----------------------------------------"
echo "ä½¿ç”¨ curl æ¥æ”¶åˆ†å—æ•°æ®ï¼Œæ˜¾ç¤ºä¼ è¾“è¿‡ç¨‹..."
echo ""
curl -v -N http://localhost:3000/chunked-data 2>&1 | grep -E "(Transfer-Encoding|Chunk|^[<>]|^Chunk)"
echo ""
echo ""

# æµ‹è¯• JSON æ•°æ®æµ
echo "ğŸ“Š æµ‹è¯• JSON æ•°æ®æµ (/chunked-json)"
echo "-----------------------------------"
echo "æ¥æ”¶åˆ†å— JSON æ•°æ®..."
echo ""
curl -s -N http://localhost:3000/chunked-json | jq '.'
echo ""
echo ""

# æµ‹è¯•å¤§æ•°æ®ä¼ è¾“ï¼ˆåªæ˜¾ç¤ºå‰å‡ è¡Œå’Œç»Ÿè®¡ä¿¡æ¯ï¼‰
echo "ğŸš€ æµ‹è¯•å¤§æ•°æ®ä¼ è¾“ (/chunked-large-data)"
echo "--------------------------------------"
echo "ä¼ è¾“ 100KB æ•°æ®ï¼Œæ˜¾ç¤ºä¼ è¾“ç»Ÿè®¡..."
echo ""

# ä½¿ç”¨ curl ä¸‹è½½å¹¶ç»Ÿè®¡
start_time=$(date +%s)
curl -s -w "ä¼ è¾“ç»Ÿè®¡:\nè¿æ¥æ—¶é—´: %{time_connect}s\nå¼€å§‹ä¼ è¾“æ—¶é—´: %{time_starttransfer}s\næ€»æ—¶é—´: %{time_total}s\nä¸‹è½½å¤§å°: %{size_download} bytes\nå¹³å‡é€Ÿåº¦: %{speed_download} bytes/s\n" \
     http://localhost:3000/chunked-large-data | head -5
echo "..."
echo "(æ˜¾ç¤ºå‰5è¡Œï¼Œå®é™…ä¼ è¾“äº†å®Œæ•´çš„ 100KB æ•°æ®)"
echo ""

# æ˜¾ç¤º HTTP å¤´ä¿¡æ¯
echo "ğŸ” æŸ¥çœ‹ HTTP å“åº”å¤´"
echo "-------------------"
echo "æ£€æŸ¥ Transfer-Encoding å¤´..."
echo ""
curl -I http://localhost:3000/chunked-data 2>/dev/null | grep -E "(HTTP|Transfer-Encoding|Content-Type|Cache-Control)"
echo ""

# ä½¿ç”¨ curl çš„è¯¦ç»†æ¨¡å¼æ˜¾ç¤ºåˆ†å—ä¿¡æ¯
echo "ğŸ”¬ è¯¦ç»†åˆ†å—ä¼ è¾“åˆ†æ"
echo "-------------------"
echo "ä½¿ç”¨ curl -v æŸ¥çœ‹è¯¦ç»†çš„åˆ†å—ä¼ è¾“è¿‡ç¨‹..."
echo ""
echo "å‘½ä»¤: curl -v -N http://localhost:3000/chunked-data"
echo "æ³¨æ„è§‚å¯Ÿä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š"
echo "- Transfer-Encoding: chunked"
echo "- æ¯ä¸ªæ•°æ®å—çš„åå…­è¿›åˆ¶é•¿åº¦"
echo "- æ•°æ®å—å†…å®¹"
echo "- æœ€åçš„ 0 é•¿åº¦å—è¡¨ç¤ºä¼ è¾“ç»“æŸ"
echo ""

# å¹¶å‘æµ‹è¯•
echo "âš¡ å¹¶å‘è¿æ¥æµ‹è¯•"
echo "---------------"
echo "å¯åŠ¨ 3 ä¸ªå¹¶å‘è¿æ¥æµ‹è¯•æœåŠ¡å™¨å¤„ç†èƒ½åŠ›..."
echo ""

# å¯åŠ¨ 3 ä¸ªåå° curl è¿›ç¨‹
for i in {1..3}; do
    echo "å¯åŠ¨è¿æ¥ $i..."
    curl -s http://localhost:3000/chunked-data > /tmp/chunk_test_$i.log &
    pids[$i]=$!
done

# ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
echo "ç­‰å¾…æ‰€æœ‰è¿æ¥å®Œæˆ..."
for i in {1..3}; do
    wait ${pids[$i]}
    lines=$(wc -l < /tmp/chunk_test_$i.log)
    echo "è¿æ¥ $i å®Œæˆï¼Œæ¥æ”¶äº† $lines è¡Œæ•°æ®"
    rm -f /tmp/chunk_test_$i.log
done

echo ""
echo "âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼"
echo ""
echo "ğŸ’¡ æç¤ºï¼š"
echo "1. åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:3000 æŸ¥çœ‹å¯è§†åŒ–æ¼”ç¤º"
echo "2. ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ç½‘ç»œé¢æ¿è§‚å¯Ÿåˆ†å—ä¼ è¾“"
echo "3. å°è¯•åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­åˆ·æ–°é¡µé¢æˆ–å…³é—­è¿æ¥ï¼Œè§‚å¯ŸæœåŠ¡å™¨æ—¥å¿—"
echo ""
echo "ğŸ“š æ›´å¤šæµ‹è¯•å‘½ä»¤ï¼š"
echo "curl -v -N http://localhost:3000/chunked-data     # æŸ¥çœ‹è¯¦ç»†ä¼ è¾“è¿‡ç¨‹"
echo "curl -s http://localhost:3000/chunked-json | jq   # æ ¼å¼åŒ– JSON è¾“å‡º"
echo "curl -w '%{time_total}\\n' http://localhost:3000/chunked-large-data > /dev/null  # æµ‹è¯•ä¼ è¾“æ—¶é—´" 